{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4bc9e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,random\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "import numpy as np\n",
    "from src.dataset2016 import load_data\n",
    "from statistics import mean\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b848bdec",
   "metadata": {},
   "source": [
    "### Set Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8a70091",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1991)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510619e8",
   "metadata": {},
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073fed64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of all training data: 165000\n",
      "# of all testing data: 55000\n",
      "# of labeled data: 1760 ( Training: 1100 Validation: 660 )\n"
     ]
    }
   ],
   "source": [
    "rate = 1 # xx% of the training data have label, rate = 2 means 2%.\n",
    "\n",
    "# Read dataset\n",
    "filename = '/data/dongxin3/2016.10a/RML2016.10a_dict.pkl'\n",
    "(mods,snrs,lbl),(X_train,Y_train),(X_train_labeled,Y_train_labeled),(X_val_labeled,Y_val_labeled),(X_test,Y_test),\\\n",
    "    (train_idx,test_idx,train_labeled_idx,val_labeled_idx)\\\n",
    "    = load_data(filename, rate)\n",
    "\n",
    "# Normalization\n",
    "X_train, X_train_labeled, X_val_labeled, X_test = normalize_data(X_train, X_train_labeled, X_val_labeled, X_test)\n",
    "\n",
    "print(\"# of all training data:\", X_train.shape[0])\n",
    "print(\"# of all testing data:\", X_test.shape[0])\n",
    "print(\"# of labeled data:\", X_train_labeled.shape[0]+X_val_labeled.shape[0], \\\n",
    "      \"( Training:\",X_train_labeled.shape[0], \"Validation:\",X_val_labeled.shape[0],\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3474daaa",
   "metadata": {},
   "source": [
    "### Train Contrastive Learning Model - Simclr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5d02472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_simclr\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "I/Qchannel (InputLayer)      [(None, 128, 2)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 105, 32)           1568      \n",
      "_________________________________________________________________\n",
      "LSTM1 (LSTM)                 (None, 105, 128)          82432     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 105, 128)          0         \n",
      "_________________________________________________________________\n",
      "LSTM2 (LSTM)                 (None, 105, 128)          131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 105, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 98, 128)           131200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "=================================================================\n",
      "Total params: 372,320\n",
      "Trainable params: 371,936\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Epoch: 1 loss: 9.468\n",
      "Write to 'saved_models/simclr/weight_0.hdf5'\n",
      "Epoch: 2 loss: 6.686\n",
      "Epoch: 3 loss: 4.802\n",
      "Epoch: 4 loss: 3.345\n",
      "Epoch: 5 loss: 2.374\n",
      "Epoch: 6 loss: 1.824\n",
      "Write to 'saved_models/simclr/weight_5.hdf5'\n",
      "Epoch: 7 loss: 1.437\n",
      "Epoch: 8 loss: 1.221\n",
      "Epoch: 9 loss: 1.049\n",
      "Epoch: 10 loss: 0.926\n",
      "Epoch: 11 loss: 0.852\n",
      "Write to 'saved_models/simclr/weight_10.hdf5'\n",
      "Epoch: 12 loss: 0.778\n",
      "Epoch: 13 loss: 0.736\n",
      "Epoch: 14 loss: 0.707\n",
      "Epoch: 15 loss: 0.657\n",
      "Epoch: 16 loss: 0.621\n",
      "Write to 'saved_models/simclr/weight_15.hdf5'\n",
      "Epoch: 17 loss: 0.603\n",
      "Epoch: 18 loss: 0.568\n",
      "Epoch: 19 loss: 0.554\n",
      "Epoch: 20 loss: 0.522\n",
      "Epoch: 21 loss: 0.529\n",
      "Write to 'saved_models/simclr/weight_20.hdf5'\n",
      "Epoch: 22 loss: 0.498\n",
      "Epoch: 23 loss: 0.485\n",
      "Epoch: 24 loss: 0.479\n",
      "Epoch: 25 loss: 0.465\n",
      "Epoch: 26 loss: 0.456\n",
      "Write to 'saved_models/simclr/weight_25.hdf5'\n",
      "Epoch: 27 loss: 0.450\n",
      "Epoch: 28 loss: 0.446\n",
      "Epoch: 29 loss: 0.438\n",
      "Epoch: 30 loss: 0.432\n",
      "Epoch: 31 loss: 0.429\n",
      "Write to 'saved_models/simclr/weight_30.hdf5'\n",
      "Epoch: 32 loss: 0.425\n",
      "Epoch: 33 loss: 0.423\n",
      "Epoch: 34 loss: 0.420\n",
      "Epoch: 35 loss: 0.417\n",
      "Epoch: 36 loss: 0.417\n",
      "Write to 'saved_models/simclr/weight_35.hdf5'\n",
      "Epoch: 37 loss: 0.415\n",
      "Epoch: 38 loss: 0.415\n",
      "Epoch: 39 loss: 0.415\n",
      "Epoch: 40 loss: 0.412\n",
      "Epoch: 41 loss: 0.411\n",
      "Write to 'saved_models/simclr/weight_40.hdf5'\n",
      "Epoch: 42 loss: 0.412\n",
      "Epoch: 43 loss: 0.410\n",
      "Epoch: 44 loss: 0.411\n",
      "Epoch: 45 loss: 0.412\n",
      "Epoch: 46 loss: 0.411\n",
      "Write to 'saved_models/simclr/weight_45.hdf5'\n",
      "Epoch: 47 loss: 0.411\n",
      "Epoch: 48 loss: 0.411\n",
      "Epoch: 49 loss: 0.411\n",
      "Epoch: 50 loss: 0.410\n",
      "Epoch: 51 loss: 0.411\n",
      "Write to 'saved_models/simclr/weight_50.hdf5'\n",
      "Epoch: 52 loss: 0.411\n",
      "Epoch: 53 loss: 0.412\n",
      "Epoch: 54 loss: 0.410\n",
      "Epoch: 55 loss: 0.411\n",
      "Epoch: 56 loss: 0.411\n",
      "Write to 'saved_models/simclr/weight_55.hdf5'\n",
      "Epoch: 57 loss: 0.412\n",
      "Epoch: 58 loss: 0.410\n",
      "Epoch: 59 loss: 0.410\n",
      "Epoch: 60 loss: 0.412\n",
      "Epoch: 61 loss: 0.410\n",
      "Write to 'saved_models/simclr/weight_60.hdf5'\n",
      "Epoch: 62 loss: 0.411\n",
      "Epoch: 63 loss: 0.411\n",
      "Epoch: 64 loss: 0.411\n",
      "Epoch: 65 loss: 0.411\n",
      "Epoch: 66 loss: 0.411\n",
      "Write to 'saved_models/simclr/weight_65.hdf5'\n",
      "Epoch: 67 loss: 0.410\n",
      "Epoch: 68 loss: 0.411\n",
      "Epoch: 69 loss: 0.410\n",
      "Epoch: 70 loss: 0.410\n",
      "Epoch: 71 loss: 0.410\n",
      "Write to 'saved_models/simclr/weight_70.hdf5'\n",
      "Epoch: 72 loss: 0.411\n",
      "Epoch: 73 loss: 0.412\n",
      "Epoch: 74 loss: 0.412\n",
      "Epoch: 75 loss: 0.413\n",
      "Epoch: 76 loss: 0.411\n",
      "Write to 'saved_models/simclr/weight_75.hdf5'\n",
      "Epoch: 77 loss: 0.411\n",
      "Epoch: 78 loss: 0.410\n",
      "Epoch: 79 loss: 0.413\n",
      "Epoch: 80 loss: 0.411\n",
      "Epoch: 81 loss: 0.411\n",
      "Write to 'saved_models/simclr/weight_80.hdf5'\n",
      "Epoch: 82 loss: 0.410\n",
      "Epoch: 83 loss: 0.411\n",
      "Epoch: 84 loss: 0.411\n",
      "Epoch: 85 loss: 0.411\n",
      "Epoch: 86 loss: 0.411\n",
      "Write to 'saved_models/simclr/weight_85.hdf5'\n",
      "Epoch: 87 loss: 0.411\n",
      "Epoch: 88 loss: 0.410\n",
      "Epoch: 89 loss: 0.412\n",
      "Epoch: 90 loss: 0.411\n",
      "Epoch: 91 loss: 0.411\n",
      "Write to 'saved_models/simclr/weight_90.hdf5'\n",
      "Epoch: 92 loss: 0.411\n",
      "Epoch: 93 loss: 0.410\n",
      "Epoch: 94 loss: 0.412\n",
      "Epoch: 95 loss: 0.411\n",
      "Epoch: 96 loss: 0.410\n",
      "Write to 'saved_models/simclr/weight_95.hdf5'\n",
      "Epoch: 97 loss: 0.411\n",
      "Epoch: 98 loss: 0.411\n",
      "Epoch: 99 loss: 0.411\n",
      "Epoch: 100 loss: 0.411\n",
      "=========== Contrastive Training Completed! ==========\n"
     ]
    }
   ],
   "source": [
    "# SimLCR\n",
    "sim_model, epoch_losses = train_simclr(X_train, batch_size=512, Epoch=100, temperature = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e895dc",
   "metadata": {},
   "source": [
    "### Show Epoch Loss Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b258084",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_epoch_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb6b85",
   "metadata": {},
   "source": [
    "### Build a classifier on the output of the encoder and tune the parameter of the encoder with labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c811f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"Tune_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "I/Qchannel (InputLayer)      [(None, 128, 2)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 105, 32)           1568      \n",
      "_________________________________________________________________\n",
      "LSTM1 (LSTM)                 (None, 105, 128)          82432     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 105, 128)          0         \n",
      "_________________________________________________________________\n",
      "LSTM2 (LSTM)                 (None, 105, 128)          131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 105, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 98, 128)           131200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "DP_1 (Dropout)               (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "DP_2 (Dropout)               (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "linear_Classifier (Dense)    (None, 11)                1419      \n",
      "=================================================================\n",
      "Total params: 364,715\n",
      "Trainable params: 280,715\n",
      "Non-trainable params: 84,000\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "3/3 - 5s - loss: 3.1880 - accuracy: 0.0964 - val_loss: 2.4487 - val_accuracy: 0.1864\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.44875, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 2/200\n",
      "3/3 - 0s - loss: 2.4641 - accuracy: 0.1382 - val_loss: 2.2722 - val_accuracy: 0.1727\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.44875 to 2.27220, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 3/200\n",
      "3/3 - 0s - loss: 2.2684 - accuracy: 0.1800 - val_loss: 2.1073 - val_accuracy: 0.2318\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.27220 to 2.10727, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 4/200\n",
      "3/3 - 0s - loss: 2.1366 - accuracy: 0.2227 - val_loss: 1.9871 - val_accuracy: 0.2985\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.10727 to 1.98709, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 5/200\n",
      "3/3 - 0s - loss: 2.0167 - accuracy: 0.2955 - val_loss: 1.9421 - val_accuracy: 0.3136\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.98709 to 1.94213, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 6/200\n",
      "3/3 - 0s - loss: 1.9973 - accuracy: 0.3027 - val_loss: 1.9257 - val_accuracy: 0.2848\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.94213 to 1.92567, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 7/200\n",
      "3/3 - 0s - loss: 1.9686 - accuracy: 0.3145 - val_loss: 1.8455 - val_accuracy: 0.3394\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.92567 to 1.84545, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 8/200\n",
      "3/3 - 0s - loss: 1.8998 - accuracy: 0.3255 - val_loss: 1.8327 - val_accuracy: 0.3576\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.84545 to 1.83272, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 9/200\n",
      "3/3 - 0s - loss: 1.8661 - accuracy: 0.3327 - val_loss: 1.8789 - val_accuracy: 0.3470\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 1.83272\n",
      "Epoch 10/200\n",
      "3/3 - 0s - loss: 1.8596 - accuracy: 0.3355 - val_loss: 1.8199 - val_accuracy: 0.3303\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.83272 to 1.81991, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 11/200\n",
      "3/3 - 0s - loss: 1.8538 - accuracy: 0.3409 - val_loss: 1.8547 - val_accuracy: 0.3561\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.81991\n",
      "Epoch 12/200\n",
      "3/3 - 0s - loss: 1.8192 - accuracy: 0.3709 - val_loss: 1.7505 - val_accuracy: 0.3833\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.81991 to 1.75050, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 13/200\n",
      "3/3 - 0s - loss: 1.8049 - accuracy: 0.3773 - val_loss: 1.7470 - val_accuracy: 0.3515\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.75050 to 1.74704, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 14/200\n",
      "3/3 - 0s - loss: 1.7825 - accuracy: 0.3555 - val_loss: 1.7493 - val_accuracy: 0.3727\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.74704\n",
      "Epoch 15/200\n",
      "3/3 - 0s - loss: 1.7974 - accuracy: 0.3891 - val_loss: 1.7485 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 1.74704\n",
      "Epoch 16/200\n",
      "3/3 - 0s - loss: 1.7536 - accuracy: 0.3818 - val_loss: 1.7246 - val_accuracy: 0.3788\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.74704 to 1.72462, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 17/200\n",
      "3/3 - 0s - loss: 1.7461 - accuracy: 0.3618 - val_loss: 1.7246 - val_accuracy: 0.3576\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.72462 to 1.72460, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 18/200\n",
      "3/3 - 0s - loss: 1.7342 - accuracy: 0.3827 - val_loss: 1.7390 - val_accuracy: 0.3742\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.72460\n",
      "Epoch 19/200\n",
      "3/3 - 0s - loss: 1.7296 - accuracy: 0.3836 - val_loss: 1.7114 - val_accuracy: 0.3712\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.72460 to 1.71135, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 20/200\n",
      "3/3 - 0s - loss: 1.7113 - accuracy: 0.3945 - val_loss: 1.6835 - val_accuracy: 0.3864\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.71135 to 1.68351, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 21/200\n",
      "3/3 - 0s - loss: 1.7093 - accuracy: 0.3855 - val_loss: 1.7055 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 1.68351\n",
      "Epoch 22/200\n",
      "3/3 - 0s - loss: 1.7175 - accuracy: 0.3900 - val_loss: 1.6988 - val_accuracy: 0.3833\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.68351\n",
      "Epoch 23/200\n",
      "3/3 - 0s - loss: 1.6855 - accuracy: 0.3973 - val_loss: 1.6928 - val_accuracy: 0.3788\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.68351\n",
      "Epoch 24/200\n",
      "3/3 - 0s - loss: 1.6756 - accuracy: 0.3964 - val_loss: 1.6997 - val_accuracy: 0.3833\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.68351\n",
      "Epoch 25/200\n",
      "3/3 - 0s - loss: 1.7008 - accuracy: 0.3882 - val_loss: 1.7096 - val_accuracy: 0.3803\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.68351\n",
      "Epoch 26/200\n",
      "3/3 - 0s - loss: 1.6950 - accuracy: 0.3918 - val_loss: 1.6778 - val_accuracy: 0.3742\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.68351 to 1.67784, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 27/200\n",
      "3/3 - 0s - loss: 1.6761 - accuracy: 0.3755 - val_loss: 1.7638 - val_accuracy: 0.3652\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.67784\n",
      "Epoch 28/200\n",
      "3/3 - 0s - loss: 1.7461 - accuracy: 0.3809 - val_loss: 1.6878 - val_accuracy: 0.3955\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.67784\n",
      "Epoch 29/200\n",
      "3/3 - 0s - loss: 1.6985 - accuracy: 0.3964 - val_loss: 1.6912 - val_accuracy: 0.3697\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.67784\n",
      "Epoch 30/200\n",
      "3/3 - 0s - loss: 1.6726 - accuracy: 0.3855 - val_loss: 1.6883 - val_accuracy: 0.3909\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.67784\n",
      "Epoch 31/200\n",
      "3/3 - 0s - loss: 1.6688 - accuracy: 0.3873 - val_loss: 1.6990 - val_accuracy: 0.3894\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 1.67784\n",
      "Epoch 32/200\n",
      "3/3 - 0s - loss: 1.6494 - accuracy: 0.4155 - val_loss: 1.6586 - val_accuracy: 0.4197\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.67784 to 1.65862, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 33/200\n",
      "3/3 - 0s - loss: 1.6746 - accuracy: 0.3936 - val_loss: 1.6628 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.65862\n",
      "Epoch 34/200\n",
      "3/3 - 0s - loss: 1.6639 - accuracy: 0.4109 - val_loss: 1.6405 - val_accuracy: 0.4152\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.65862 to 1.64052, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 35/200\n",
      "3/3 - 0s - loss: 1.6410 - accuracy: 0.4045 - val_loss: 1.6755 - val_accuracy: 0.3909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00035: val_loss did not improve from 1.64052\n",
      "Epoch 36/200\n",
      "3/3 - 0s - loss: 1.6445 - accuracy: 0.4145 - val_loss: 1.6809 - val_accuracy: 0.3924\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.64052\n",
      "Epoch 37/200\n",
      "3/3 - 0s - loss: 1.6594 - accuracy: 0.4109 - val_loss: 1.6498 - val_accuracy: 0.4076\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.64052\n",
      "Epoch 38/200\n",
      "3/3 - 0s - loss: 1.6659 - accuracy: 0.4091 - val_loss: 1.6673 - val_accuracy: 0.4227\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.64052\n",
      "Epoch 39/200\n",
      "3/3 - 0s - loss: 1.6321 - accuracy: 0.4045 - val_loss: 1.7059 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.64052\n",
      "Epoch 40/200\n",
      "3/3 - 0s - loss: 1.6709 - accuracy: 0.4064 - val_loss: 1.6408 - val_accuracy: 0.4242\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.64052\n",
      "Epoch 41/200\n",
      "3/3 - 0s - loss: 1.6059 - accuracy: 0.4264 - val_loss: 1.6623 - val_accuracy: 0.4106\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.64052\n",
      "Epoch 42/200\n",
      "3/3 - 0s - loss: 1.6042 - accuracy: 0.4218 - val_loss: 1.7013 - val_accuracy: 0.3909\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.64052\n",
      "Epoch 43/200\n",
      "3/3 - 0s - loss: 1.6615 - accuracy: 0.4100 - val_loss: 1.7256 - val_accuracy: 0.3864\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.64052\n",
      "Epoch 44/200\n",
      "3/3 - 0s - loss: 1.6668 - accuracy: 0.4145 - val_loss: 1.6622 - val_accuracy: 0.3788\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.64052\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
      "Epoch 45/200\n",
      "3/3 - 0s - loss: 1.6487 - accuracy: 0.4173 - val_loss: 1.6786 - val_accuracy: 0.3712\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.64052\n",
      "Epoch 46/200\n",
      "3/3 - 0s - loss: 1.6379 - accuracy: 0.4145 - val_loss: 1.6876 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 1.64052\n",
      "Epoch 47/200\n",
      "3/3 - 0s - loss: 1.6030 - accuracy: 0.4364 - val_loss: 1.6681 - val_accuracy: 0.4076\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.64052\n",
      "Epoch 48/200\n",
      "3/3 - 0s - loss: 1.6282 - accuracy: 0.4100 - val_loss: 1.6689 - val_accuracy: 0.4136\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.64052\n",
      "Epoch 49/200\n",
      "3/3 - 0s - loss: 1.6214 - accuracy: 0.4255 - val_loss: 1.6484 - val_accuracy: 0.3970\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 1.64052\n",
      "Epoch 50/200\n",
      "3/3 - 0s - loss: 1.6144 - accuracy: 0.4145 - val_loss: 1.6684 - val_accuracy: 0.4121\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.64052\n",
      "Epoch 51/200\n",
      "3/3 - 0s - loss: 1.6012 - accuracy: 0.4155 - val_loss: 1.7198 - val_accuracy: 0.3803\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.64052\n",
      "Epoch 52/200\n",
      "3/3 - 0s - loss: 1.6182 - accuracy: 0.4345 - val_loss: 1.6384 - val_accuracy: 0.4091\n",
      "\n",
      "Epoch 00052: val_loss improved from 1.64052 to 1.63837, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 53/200\n",
      "3/3 - 0s - loss: 1.5882 - accuracy: 0.4227 - val_loss: 1.6231 - val_accuracy: 0.4136\n",
      "\n",
      "Epoch 00053: val_loss improved from 1.63837 to 1.62310, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 54/200\n",
      "3/3 - 0s - loss: 1.5974 - accuracy: 0.4382 - val_loss: 1.6188 - val_accuracy: 0.4197\n",
      "\n",
      "Epoch 00054: val_loss improved from 1.62310 to 1.61884, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 55/200\n",
      "3/3 - 0s - loss: 1.5760 - accuracy: 0.4409 - val_loss: 1.6074 - val_accuracy: 0.4303\n",
      "\n",
      "Epoch 00055: val_loss improved from 1.61884 to 1.60743, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 56/200\n",
      "3/3 - 0s - loss: 1.5671 - accuracy: 0.4382 - val_loss: 1.6794 - val_accuracy: 0.3939\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.60743\n",
      "Epoch 57/200\n",
      "3/3 - 0s - loss: 1.5950 - accuracy: 0.4345 - val_loss: 1.6316 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 1.60743\n",
      "Epoch 58/200\n",
      "3/3 - 0s - loss: 1.5515 - accuracy: 0.4409 - val_loss: 1.6441 - val_accuracy: 0.4015\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.60743\n",
      "Epoch 59/200\n",
      "3/3 - 0s - loss: 1.5769 - accuracy: 0.4182 - val_loss: 1.6794 - val_accuracy: 0.4076\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.60743\n",
      "Epoch 60/200\n",
      "3/3 - 0s - loss: 1.5712 - accuracy: 0.4400 - val_loss: 1.6456 - val_accuracy: 0.4121\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.60743\n",
      "Epoch 61/200\n",
      "3/3 - 0s - loss: 1.5596 - accuracy: 0.4227 - val_loss: 1.6402 - val_accuracy: 0.3939\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.60743\n",
      "Epoch 62/200\n",
      "3/3 - 0s - loss: 1.5878 - accuracy: 0.4173 - val_loss: 1.6349 - val_accuracy: 0.4015\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.60743\n",
      "Epoch 63/200\n",
      "3/3 - 0s - loss: 1.5743 - accuracy: 0.4273 - val_loss: 1.6364 - val_accuracy: 0.3894\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.60743\n",
      "Epoch 64/200\n",
      "3/3 - 0s - loss: 1.5657 - accuracy: 0.4482 - val_loss: 1.6695 - val_accuracy: 0.3833\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.60743\n",
      "Epoch 65/200\n",
      "3/3 - 0s - loss: 1.5988 - accuracy: 0.4255 - val_loss: 1.7367 - val_accuracy: 0.3848\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.60743\n",
      "\n",
      "Epoch 00065: ReduceLROnPlateau reducing learning rate to 0.006399999558925629.\n",
      "Epoch 66/200\n",
      "3/3 - 0s - loss: 1.5923 - accuracy: 0.4336 - val_loss: 1.6484 - val_accuracy: 0.4121\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.60743\n",
      "Epoch 67/200\n",
      "3/3 - 0s - loss: 1.5629 - accuracy: 0.4400 - val_loss: 1.6826 - val_accuracy: 0.3742\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.60743\n",
      "Epoch 68/200\n",
      "3/3 - 0s - loss: 1.5999 - accuracy: 0.4173 - val_loss: 1.6236 - val_accuracy: 0.4030\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.60743\n",
      "Epoch 69/200\n",
      "3/3 - 0s - loss: 1.5305 - accuracy: 0.4527 - val_loss: 1.6780 - val_accuracy: 0.4076\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.60743\n",
      "Epoch 70/200\n",
      "3/3 - 0s - loss: 1.5664 - accuracy: 0.4382 - val_loss: 1.6432 - val_accuracy: 0.4197\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.60743\n",
      "Epoch 71/200\n",
      "3/3 - 0s - loss: 1.5254 - accuracy: 0.4591 - val_loss: 1.6140 - val_accuracy: 0.4303\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.60743\n",
      "Epoch 72/200\n",
      "3/3 - 0s - loss: 1.5221 - accuracy: 0.4527 - val_loss: 1.6321 - val_accuracy: 0.4182\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.60743\n",
      "Epoch 73/200\n",
      "3/3 - 0s - loss: 1.5434 - accuracy: 0.4400 - val_loss: 1.6220 - val_accuracy: 0.3985\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.60743\n",
      "Epoch 74/200\n",
      "3/3 - 0s - loss: 1.5085 - accuracy: 0.4591 - val_loss: 1.6128 - val_accuracy: 0.4121\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.60743\n",
      "Epoch 75/200\n",
      "3/3 - 0s - loss: 1.5121 - accuracy: 0.4636 - val_loss: 1.6278 - val_accuracy: 0.4242\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.60743\n",
      "\n",
      "Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0051199994981288915.\n",
      "Epoch 76/200\n",
      "3/3 - 0s - loss: 1.4921 - accuracy: 0.4855 - val_loss: 1.6371 - val_accuracy: 0.4136\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.60743\n",
      "Epoch 77/200\n",
      "3/3 - 0s - loss: 1.4760 - accuracy: 0.4873 - val_loss: 1.6318 - val_accuracy: 0.4242\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.60743\n",
      "Epoch 78/200\n",
      "3/3 - 0s - loss: 1.4763 - accuracy: 0.4745 - val_loss: 1.6132 - val_accuracy: 0.4288\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.60743\n",
      "Epoch 79/200\n",
      "3/3 - 0s - loss: 1.5073 - accuracy: 0.4609 - val_loss: 1.6190 - val_accuracy: 0.4333\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.60743\n",
      "Epoch 80/200\n",
      "3/3 - 0s - loss: 1.4869 - accuracy: 0.4609 - val_loss: 1.6309 - val_accuracy: 0.4242\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.60743\n",
      "Epoch 81/200\n",
      "3/3 - 0s - loss: 1.4922 - accuracy: 0.4564 - val_loss: 1.6269 - val_accuracy: 0.4227\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.60743\n",
      "Epoch 82/200\n",
      "3/3 - 0s - loss: 1.4763 - accuracy: 0.4836 - val_loss: 1.6126 - val_accuracy: 0.4379\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.60743\n",
      "Epoch 83/200\n",
      "3/3 - 0s - loss: 1.4974 - accuracy: 0.4745 - val_loss: 1.6193 - val_accuracy: 0.4167\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.60743\n",
      "Epoch 84/200\n",
      "3/3 - 0s - loss: 1.4590 - accuracy: 0.5045 - val_loss: 1.6259 - val_accuracy: 0.4394\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.60743\n",
      "Epoch 85/200\n",
      "3/3 - 0s - loss: 1.5043 - accuracy: 0.4691 - val_loss: 1.6044 - val_accuracy: 0.4288\n",
      "\n",
      "Epoch 00085: val_loss improved from 1.60743 to 1.60440, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 86/200\n",
      "3/3 - 0s - loss: 1.5056 - accuracy: 0.4700 - val_loss: 1.6166 - val_accuracy: 0.4364\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.60440\n",
      "Epoch 87/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 - 0s - loss: 1.4682 - accuracy: 0.4891 - val_loss: 1.6300 - val_accuracy: 0.4318\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 1.60440\n",
      "Epoch 88/200\n",
      "3/3 - 0s - loss: 1.4757 - accuracy: 0.4809 - val_loss: 1.6248 - val_accuracy: 0.4273\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 1.60440\n",
      "Epoch 89/200\n",
      "3/3 - 0s - loss: 1.4619 - accuracy: 0.4800 - val_loss: 1.6244 - val_accuracy: 0.4258\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 1.60440\n",
      "Epoch 90/200\n",
      "3/3 - 0s - loss: 1.4686 - accuracy: 0.4700 - val_loss: 1.5965 - val_accuracy: 0.4394\n",
      "\n",
      "Epoch 00090: val_loss improved from 1.60440 to 1.59651, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 91/200\n",
      "3/3 - 0s - loss: 1.4733 - accuracy: 0.4727 - val_loss: 1.6021 - val_accuracy: 0.4242\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 1.59651\n",
      "Epoch 92/200\n",
      "3/3 - 0s - loss: 1.4246 - accuracy: 0.5018 - val_loss: 1.6375 - val_accuracy: 0.4273\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 1.59651\n",
      "Epoch 93/200\n",
      "3/3 - 0s - loss: 1.4716 - accuracy: 0.4818 - val_loss: 1.6259 - val_accuracy: 0.4364\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 1.59651\n",
      "Epoch 94/200\n",
      "3/3 - 0s - loss: 1.4496 - accuracy: 0.4836 - val_loss: 1.6134 - val_accuracy: 0.4394\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 1.59651\n",
      "Epoch 95/200\n",
      "3/3 - 0s - loss: 1.4613 - accuracy: 0.4955 - val_loss: 1.6393 - val_accuracy: 0.4364\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 1.59651\n",
      "Epoch 96/200\n",
      "3/3 - 0s - loss: 1.4987 - accuracy: 0.4764 - val_loss: 1.6012 - val_accuracy: 0.4409\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 1.59651\n",
      "Epoch 97/200\n",
      "3/3 - 0s - loss: 1.5449 - accuracy: 0.4609 - val_loss: 1.6242 - val_accuracy: 0.4288\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 1.59651\n",
      "Epoch 98/200\n",
      "3/3 - 0s - loss: 1.4816 - accuracy: 0.4882 - val_loss: 1.6592 - val_accuracy: 0.4091\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 1.59651\n",
      "Epoch 99/200\n",
      "3/3 - 0s - loss: 1.5230 - accuracy: 0.4627 - val_loss: 1.5911 - val_accuracy: 0.4394\n",
      "\n",
      "Epoch 00099: val_loss improved from 1.59651 to 1.59107, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 100/200\n",
      "3/3 - 0s - loss: 1.4702 - accuracy: 0.4918 - val_loss: 1.6138 - val_accuracy: 0.4258\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 1.59107\n",
      "Epoch 101/200\n",
      "3/3 - 0s - loss: 1.4854 - accuracy: 0.4745 - val_loss: 1.5804 - val_accuracy: 0.4424\n",
      "\n",
      "Epoch 00101: val_loss improved from 1.59107 to 1.58036, saving model to ./saved_models/weight_tune.hdf5\n",
      "Epoch 102/200\n",
      "3/3 - 0s - loss: 1.4325 - accuracy: 0.4809 - val_loss: 1.6260 - val_accuracy: 0.4227\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 1.58036\n",
      "Epoch 103/200\n",
      "3/3 - 0s - loss: 1.4524 - accuracy: 0.4891 - val_loss: 1.6192 - val_accuracy: 0.4197\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 1.58036\n",
      "Epoch 104/200\n",
      "3/3 - 0s - loss: 1.4656 - accuracy: 0.4718 - val_loss: 1.5911 - val_accuracy: 0.4455\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 1.58036\n",
      "Epoch 105/200\n",
      "3/3 - 0s - loss: 1.4389 - accuracy: 0.4973 - val_loss: 1.5929 - val_accuracy: 0.4318\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 1.58036\n",
      "Epoch 106/200\n",
      "3/3 - 0s - loss: 1.4297 - accuracy: 0.5082 - val_loss: 1.5930 - val_accuracy: 0.4409\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 1.58036\n",
      "Epoch 107/200\n",
      "3/3 - 0s - loss: 1.4290 - accuracy: 0.5173 - val_loss: 1.5989 - val_accuracy: 0.4409\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 1.58036\n",
      "Epoch 108/200\n",
      "3/3 - 0s - loss: 1.4359 - accuracy: 0.5000 - val_loss: 1.6136 - val_accuracy: 0.4500\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 1.58036\n",
      "Epoch 109/200\n",
      "3/3 - 0s - loss: 1.4434 - accuracy: 0.4945 - val_loss: 1.5835 - val_accuracy: 0.4364\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 1.58036\n",
      "Epoch 110/200\n",
      "3/3 - 0s - loss: 1.4139 - accuracy: 0.4900 - val_loss: 1.5876 - val_accuracy: 0.4424\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 1.58036\n",
      "Epoch 111/200\n",
      "3/3 - 0s - loss: 1.3922 - accuracy: 0.5182 - val_loss: 1.6149 - val_accuracy: 0.4348\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 1.58036\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 0.004095999523997307.\n",
      "Epoch 112/200\n",
      "3/3 - 0s - loss: 1.4113 - accuracy: 0.5064 - val_loss: 1.5936 - val_accuracy: 0.4303\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 1.58036\n",
      "Epoch 113/200\n",
      "3/3 - 0s - loss: 1.3989 - accuracy: 0.5018 - val_loss: 1.5942 - val_accuracy: 0.4409\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 1.58036\n",
      "Epoch 114/200\n",
      "3/3 - 0s - loss: 1.4099 - accuracy: 0.5009 - val_loss: 1.5948 - val_accuracy: 0.4500\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 1.58036\n",
      "Epoch 115/200\n",
      "3/3 - 0s - loss: 1.3854 - accuracy: 0.5336 - val_loss: 1.6211 - val_accuracy: 0.4379\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 1.58036\n",
      "Epoch 116/200\n",
      "3/3 - 0s - loss: 1.3985 - accuracy: 0.5264 - val_loss: 1.6003 - val_accuracy: 0.4636\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 1.58036\n",
      "Epoch 117/200\n",
      "3/3 - 0s - loss: 1.3893 - accuracy: 0.5073 - val_loss: 1.5981 - val_accuracy: 0.4576\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 1.58036\n",
      "Epoch 118/200\n",
      "3/3 - 0s - loss: 1.3972 - accuracy: 0.5218 - val_loss: 1.6075 - val_accuracy: 0.4409\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 1.58036\n",
      "Epoch 119/200\n",
      "3/3 - 0s - loss: 1.3977 - accuracy: 0.4991 - val_loss: 1.6694 - val_accuracy: 0.4303\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 1.58036\n",
      "Epoch 120/200\n",
      "3/3 - 0s - loss: 1.4422 - accuracy: 0.4873 - val_loss: 1.6199 - val_accuracy: 0.4409\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 1.58036\n",
      "Epoch 121/200\n",
      "3/3 - 0s - loss: 1.4207 - accuracy: 0.5218 - val_loss: 1.6425 - val_accuracy: 0.4409\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 1.58036\n",
      "\n",
      "Epoch 00121: ReduceLROnPlateau reducing learning rate to 0.0032767996191978457.\n",
      "Epoch 122/200\n",
      "3/3 - 0s - loss: 1.4252 - accuracy: 0.5036 - val_loss: 1.6273 - val_accuracy: 0.4364\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 1.58036\n",
      "Epoch 123/200\n",
      "3/3 - 0s - loss: 1.4017 - accuracy: 0.5164 - val_loss: 1.6183 - val_accuracy: 0.4470\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 1.58036\n",
      "Epoch 124/200\n",
      "3/3 - 0s - loss: 1.4054 - accuracy: 0.5109 - val_loss: 1.6208 - val_accuracy: 0.4288\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 1.58036\n",
      "Epoch 125/200\n",
      "3/3 - 0s - loss: 1.3559 - accuracy: 0.5445 - val_loss: 1.6319 - val_accuracy: 0.4364\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 1.58036\n",
      "Epoch 126/200\n",
      "3/3 - 0s - loss: 1.3621 - accuracy: 0.5445 - val_loss: 1.6601 - val_accuracy: 0.4424\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 1.58036\n",
      "Epoch 127/200\n",
      "3/3 - 0s - loss: 1.3814 - accuracy: 0.5427 - val_loss: 1.6231 - val_accuracy: 0.4515\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 1.58036\n",
      "Epoch 128/200\n",
      "3/3 - 0s - loss: 1.3487 - accuracy: 0.5445 - val_loss: 1.6087 - val_accuracy: 0.4470\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 1.58036\n",
      "Epoch 129/200\n",
      "3/3 - 0s - loss: 1.3523 - accuracy: 0.5327 - val_loss: 1.5976 - val_accuracy: 0.4439\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 1.58036\n",
      "Epoch 130/200\n",
      "3/3 - 0s - loss: 1.3343 - accuracy: 0.5373 - val_loss: 1.6023 - val_accuracy: 0.4424\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 1.58036\n",
      "Epoch 131/200\n",
      "3/3 - 0s - loss: 1.3632 - accuracy: 0.5255 - val_loss: 1.5918 - val_accuracy: 0.4485\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 1.58036\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 0.0026214396581053737.\n",
      "Epoch 00131: early stopping\n",
      "=========== Tuning Completed! ==========\n",
      "Save model to 'saved_models/weight_tune.hdf5'\n"
     ]
    }
   ],
   "source": [
    "# Tune Model\n",
    "tune_model = train_tune(X_train_labeled, Y_train_labeled, X_val_labeled, Y_val_labeled, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b8d5c",
   "metadata": {},
   "source": [
    "### Train the encoder + classifier from the very beginning under supervised way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aa7304e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sup_Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "I/Qchannel (InputLayer)      [(None, 128, 2)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 105, 32)           1568      \n",
      "_________________________________________________________________\n",
      "LSTM1 (LSTM)                 (None, 105, 128)          82432     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 105, 128)          0         \n",
      "_________________________________________________________________\n",
      "LSTM2 (LSTM)                 (None, 105, 128)          131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 105, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 98, 128)           131200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "FC1 (Dense)                  (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "linear_Classifier (Dense)    (None, 11)                1419      \n",
      "=================================================================\n",
      "Total params: 364,715\n",
      "Trainable params: 364,715\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/500\n",
      "3/3 - 3s - loss: 2.4928 - accuracy: 0.0945 - val_loss: 3.2133 - val_accuracy: 0.1121\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.21333, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 2/500\n",
      "3/3 - 0s - loss: 3.6537 - accuracy: 0.1082 - val_loss: 2.4552 - val_accuracy: 0.1258\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.21333 to 2.45524, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 3/500\n",
      "3/3 - 0s - loss: 2.4723 - accuracy: 0.1182 - val_loss: 2.4154 - val_accuracy: 0.1758\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.45524 to 2.41536, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 4/500\n",
      "3/3 - 0s - loss: 2.4224 - accuracy: 0.1573 - val_loss: 2.3923 - val_accuracy: 0.1667\n",
      "\n",
      "Epoch 00004: val_loss improved from 2.41536 to 2.39228, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 5/500\n",
      "3/3 - 0s - loss: 2.3950 - accuracy: 0.1318 - val_loss: 2.4300 - val_accuracy: 0.1303\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.39228\n",
      "Epoch 6/500\n",
      "3/3 - 0s - loss: 2.4615 - accuracy: 0.1582 - val_loss: 2.2799 - val_accuracy: 0.2045\n",
      "\n",
      "Epoch 00006: val_loss improved from 2.39228 to 2.27990, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 7/500\n",
      "3/3 - 0s - loss: 2.3410 - accuracy: 0.1655 - val_loss: 2.2166 - val_accuracy: 0.1970\n",
      "\n",
      "Epoch 00007: val_loss improved from 2.27990 to 2.21663, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 8/500\n",
      "3/3 - 0s - loss: 2.2535 - accuracy: 0.1873 - val_loss: 2.1191 - val_accuracy: 0.2152\n",
      "\n",
      "Epoch 00008: val_loss improved from 2.21663 to 2.11915, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 9/500\n",
      "3/3 - 0s - loss: 2.1575 - accuracy: 0.2145 - val_loss: 2.1098 - val_accuracy: 0.2545\n",
      "\n",
      "Epoch 00009: val_loss improved from 2.11915 to 2.10978, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 10/500\n",
      "3/3 - 0s - loss: 2.1540 - accuracy: 0.2300 - val_loss: 2.0923 - val_accuracy: 0.2742\n",
      "\n",
      "Epoch 00010: val_loss improved from 2.10978 to 2.09227, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 11/500\n",
      "3/3 - 0s - loss: 2.1234 - accuracy: 0.2482 - val_loss: 2.0409 - val_accuracy: 0.2576\n",
      "\n",
      "Epoch 00011: val_loss improved from 2.09227 to 2.04091, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 12/500\n",
      "3/3 - 0s - loss: 2.0540 - accuracy: 0.2727 - val_loss: 1.9824 - val_accuracy: 0.2758\n",
      "\n",
      "Epoch 00012: val_loss improved from 2.04091 to 1.98240, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 13/500\n",
      "3/3 - 0s - loss: 2.0039 - accuracy: 0.2682 - val_loss: 1.9766 - val_accuracy: 0.2864\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.98240 to 1.97663, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 14/500\n",
      "3/3 - 0s - loss: 2.0274 - accuracy: 0.2755 - val_loss: 1.9470 - val_accuracy: 0.3424\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.97663 to 1.94699, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 15/500\n",
      "3/3 - 0s - loss: 2.0037 - accuracy: 0.3000 - val_loss: 1.9276 - val_accuracy: 0.3318\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.94699 to 1.92765, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 16/500\n",
      "3/3 - 0s - loss: 2.0032 - accuracy: 0.2945 - val_loss: 1.9576 - val_accuracy: 0.3000\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 1.92765\n",
      "Epoch 17/500\n",
      "3/3 - 0s - loss: 2.0018 - accuracy: 0.2764 - val_loss: 1.9790 - val_accuracy: 0.3212\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 1.92765\n",
      "Epoch 18/500\n",
      "3/3 - 0s - loss: 1.9876 - accuracy: 0.3009 - val_loss: 1.9522 - val_accuracy: 0.3273\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 1.92765\n",
      "Epoch 19/500\n",
      "3/3 - 0s - loss: 1.9626 - accuracy: 0.3018 - val_loss: 1.8875 - val_accuracy: 0.3258\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.92765 to 1.88750, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 20/500\n",
      "3/3 - 0s - loss: 1.8985 - accuracy: 0.3364 - val_loss: 1.8516 - val_accuracy: 0.3485\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.88750 to 1.85159, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 21/500\n",
      "3/3 - 0s - loss: 1.8851 - accuracy: 0.3182 - val_loss: 1.8482 - val_accuracy: 0.3470\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.85159 to 1.84822, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 22/500\n",
      "3/3 - 0s - loss: 1.8665 - accuracy: 0.3500 - val_loss: 1.8818 - val_accuracy: 0.3167\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.84822\n",
      "Epoch 23/500\n",
      "3/3 - 0s - loss: 1.9030 - accuracy: 0.3118 - val_loss: 1.8688 - val_accuracy: 0.3227\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 1.84822\n",
      "Epoch 24/500\n",
      "3/3 - 0s - loss: 1.8903 - accuracy: 0.3309 - val_loss: 1.8518 - val_accuracy: 0.3303\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.84822\n",
      "Epoch 25/500\n",
      "3/3 - 0s - loss: 1.8661 - accuracy: 0.3391 - val_loss: 1.8416 - val_accuracy: 0.3258\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.84822 to 1.84158, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 26/500\n",
      "3/3 - 0s - loss: 1.8602 - accuracy: 0.3218 - val_loss: 1.8318 - val_accuracy: 0.3409\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.84158 to 1.83185, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 27/500\n",
      "3/3 - 0s - loss: 1.8364 - accuracy: 0.3418 - val_loss: 1.8466 - val_accuracy: 0.3394\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.83185\n",
      "Epoch 28/500\n",
      "3/3 - 0s - loss: 1.8317 - accuracy: 0.3436 - val_loss: 1.7793 - val_accuracy: 0.3530\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.83185 to 1.77930, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 29/500\n",
      "3/3 - 0s - loss: 1.8009 - accuracy: 0.3355 - val_loss: 1.8301 - val_accuracy: 0.3561\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.77930\n",
      "Epoch 30/500\n",
      "3/3 - 0s - loss: 1.8291 - accuracy: 0.3555 - val_loss: 1.7530 - val_accuracy: 0.3894\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.77930 to 1.75298, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 31/500\n",
      "3/3 - 0s - loss: 1.7759 - accuracy: 0.3536 - val_loss: 1.7402 - val_accuracy: 0.3652\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.75298 to 1.74022, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 32/500\n",
      "3/3 - 0s - loss: 1.7382 - accuracy: 0.3691 - val_loss: 1.7437 - val_accuracy: 0.3530\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 1.74022\n",
      "Epoch 33/500\n",
      "3/3 - 0s - loss: 1.7628 - accuracy: 0.3482 - val_loss: 1.9090 - val_accuracy: 0.3152\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 1.74022\n",
      "Epoch 34/500\n",
      "3/3 - 0s - loss: 1.9494 - accuracy: 0.3127 - val_loss: 1.7911 - val_accuracy: 0.3530\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.74022\n",
      "Epoch 35/500\n",
      "3/3 - 0s - loss: 1.8301 - accuracy: 0.3327 - val_loss: 1.7446 - val_accuracy: 0.3591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00035: val_loss did not improve from 1.74022\n",
      "Epoch 36/500\n",
      "3/3 - 0s - loss: 1.7657 - accuracy: 0.3500 - val_loss: 1.8046 - val_accuracy: 0.3394\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 1.74022\n",
      "Epoch 37/500\n",
      "3/3 - 0s - loss: 1.7449 - accuracy: 0.3564 - val_loss: 1.8055 - val_accuracy: 0.3545\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 1.74022\n",
      "Epoch 38/500\n",
      "3/3 - 0s - loss: 1.7787 - accuracy: 0.3545 - val_loss: 1.7628 - val_accuracy: 0.3773\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 1.74022\n",
      "Epoch 39/500\n",
      "3/3 - 0s - loss: 1.7024 - accuracy: 0.3764 - val_loss: 1.8857 - val_accuracy: 0.3258\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 1.74022\n",
      "Epoch 40/500\n",
      "3/3 - 0s - loss: 1.7101 - accuracy: 0.3664 - val_loss: 1.8196 - val_accuracy: 0.3394\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 1.74022\n",
      "Epoch 41/500\n",
      "3/3 - 0s - loss: 1.7087 - accuracy: 0.3682 - val_loss: 1.7880 - val_accuracy: 0.3333\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 1.74022\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
      "Epoch 42/500\n",
      "3/3 - 0s - loss: 1.6740 - accuracy: 0.3809 - val_loss: 1.7989 - val_accuracy: 0.3439\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 1.74022\n",
      "Epoch 43/500\n",
      "3/3 - 0s - loss: 1.6860 - accuracy: 0.3900 - val_loss: 1.7548 - val_accuracy: 0.3621\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 1.74022\n",
      "Epoch 44/500\n",
      "3/3 - 0s - loss: 1.6200 - accuracy: 0.4164 - val_loss: 1.7407 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 1.74022\n",
      "Epoch 45/500\n",
      "3/3 - 0s - loss: 1.6301 - accuracy: 0.4000 - val_loss: 1.7639 - val_accuracy: 0.3455\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 1.74022\n",
      "Epoch 46/500\n",
      "3/3 - 0s - loss: 1.6393 - accuracy: 0.3845 - val_loss: 1.7372 - val_accuracy: 0.3667\n",
      "\n",
      "Epoch 00046: val_loss improved from 1.74022 to 1.73724, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 47/500\n",
      "3/3 - 0s - loss: 1.6325 - accuracy: 0.3973 - val_loss: 1.7697 - val_accuracy: 0.3530\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 1.73724\n",
      "Epoch 48/500\n",
      "3/3 - 0s - loss: 1.5656 - accuracy: 0.4136 - val_loss: 1.7623 - val_accuracy: 0.3682\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 1.73724\n",
      "Epoch 49/500\n",
      "3/3 - 0s - loss: 1.5747 - accuracy: 0.4064 - val_loss: 1.6959 - val_accuracy: 0.3773\n",
      "\n",
      "Epoch 00049: val_loss improved from 1.73724 to 1.69591, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 50/500\n",
      "3/3 - 0s - loss: 1.5605 - accuracy: 0.4082 - val_loss: 1.7638 - val_accuracy: 0.3773\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 1.69591\n",
      "Epoch 51/500\n",
      "3/3 - 0s - loss: 1.6059 - accuracy: 0.4091 - val_loss: 1.7131 - val_accuracy: 0.3682\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 1.69591\n",
      "Epoch 52/500\n",
      "3/3 - 0s - loss: 1.5870 - accuracy: 0.4136 - val_loss: 2.0770 - val_accuracy: 0.3227\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 1.69591\n",
      "Epoch 53/500\n",
      "3/3 - 0s - loss: 1.7332 - accuracy: 0.3764 - val_loss: 1.7995 - val_accuracy: 0.3561\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 1.69591\n",
      "Epoch 54/500\n",
      "3/3 - 0s - loss: 1.6506 - accuracy: 0.4091 - val_loss: 1.7796 - val_accuracy: 0.3606\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 1.69591\n",
      "Epoch 55/500\n",
      "3/3 - 0s - loss: 1.5799 - accuracy: 0.4127 - val_loss: 1.7058 - val_accuracy: 0.3758\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 1.69591\n",
      "Epoch 56/500\n",
      "3/3 - 0s - loss: 1.5363 - accuracy: 0.4264 - val_loss: 1.7620 - val_accuracy: 0.3652\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 1.69591\n",
      "Epoch 57/500\n",
      "3/3 - 0s - loss: 1.5772 - accuracy: 0.4227 - val_loss: 1.6939 - val_accuracy: 0.3909\n",
      "\n",
      "Epoch 00057: val_loss improved from 1.69591 to 1.69391, saving model to ./saved_models/weight_sup.hdf5\n",
      "Epoch 58/500\n",
      "3/3 - 0s - loss: 1.5382 - accuracy: 0.4445 - val_loss: 1.7911 - val_accuracy: 0.3576\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 1.69391\n",
      "Epoch 59/500\n",
      "3/3 - 0s - loss: 1.5573 - accuracy: 0.4191 - val_loss: 1.6988 - val_accuracy: 0.3621\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 1.69391\n",
      "Epoch 60/500\n",
      "3/3 - 0s - loss: 1.4768 - accuracy: 0.4518 - val_loss: 1.7585 - val_accuracy: 0.3742\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 1.69391\n",
      "Epoch 61/500\n",
      "3/3 - 0s - loss: 1.4953 - accuracy: 0.4400 - val_loss: 1.7531 - val_accuracy: 0.3773\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 1.69391\n",
      "Epoch 62/500\n",
      "3/3 - 0s - loss: 1.4478 - accuracy: 0.4500 - val_loss: 1.7671 - val_accuracy: 0.3652\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 1.69391\n",
      "Epoch 63/500\n",
      "3/3 - 0s - loss: 1.4643 - accuracy: 0.4491 - val_loss: 1.7121 - val_accuracy: 0.3818\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 1.69391\n",
      "Epoch 64/500\n",
      "3/3 - 0s - loss: 1.4428 - accuracy: 0.4509 - val_loss: 1.7053 - val_accuracy: 0.3848\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 1.69391\n",
      "Epoch 65/500\n",
      "3/3 - 0s - loss: 1.4139 - accuracy: 0.4673 - val_loss: 1.7592 - val_accuracy: 0.3561\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 1.69391\n",
      "Epoch 66/500\n",
      "3/3 - 0s - loss: 1.4492 - accuracy: 0.4655 - val_loss: 1.7915 - val_accuracy: 0.3682\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 1.69391\n",
      "Epoch 67/500\n",
      "3/3 - 0s - loss: 1.4787 - accuracy: 0.4464 - val_loss: 1.8557 - val_accuracy: 0.3803\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 1.69391\n",
      "\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.006399999558925629.\n",
      "Epoch 68/500\n",
      "3/3 - 0s - loss: 1.5076 - accuracy: 0.4545 - val_loss: 1.8685 - val_accuracy: 0.3424\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 1.69391\n",
      "Epoch 69/500\n",
      "3/3 - 0s - loss: 1.4611 - accuracy: 0.4664 - val_loss: 1.8650 - val_accuracy: 0.3652\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 1.69391\n",
      "Epoch 70/500\n",
      "3/3 - 0s - loss: 1.4404 - accuracy: 0.4436 - val_loss: 1.8283 - val_accuracy: 0.3606\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 1.69391\n",
      "Epoch 71/500\n",
      "3/3 - 0s - loss: 1.4239 - accuracy: 0.4664 - val_loss: 1.8166 - val_accuracy: 0.3697\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 1.69391\n",
      "Epoch 72/500\n",
      "3/3 - 0s - loss: 1.3844 - accuracy: 0.4755 - val_loss: 1.7700 - val_accuracy: 0.3742\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 1.69391\n",
      "Epoch 73/500\n",
      "3/3 - 0s - loss: 1.3572 - accuracy: 0.4836 - val_loss: 1.8584 - val_accuracy: 0.3970\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 1.69391\n",
      "Epoch 74/500\n",
      "3/3 - 0s - loss: 1.3652 - accuracy: 0.4682 - val_loss: 1.8004 - val_accuracy: 0.3864\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 1.69391\n",
      "Epoch 75/500\n",
      "3/3 - 0s - loss: 1.3531 - accuracy: 0.4809 - val_loss: 1.7855 - val_accuracy: 0.3939\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 1.69391\n",
      "Epoch 76/500\n",
      "3/3 - 0s - loss: 1.3188 - accuracy: 0.4918 - val_loss: 1.9382 - val_accuracy: 0.3561\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 1.69391\n",
      "Epoch 77/500\n",
      "3/3 - 0s - loss: 1.3634 - accuracy: 0.4873 - val_loss: 1.8116 - val_accuracy: 0.3879\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 1.69391\n",
      "\n",
      "Epoch 00077: ReduceLROnPlateau reducing learning rate to 0.0051199994981288915.\n",
      "Epoch 78/500\n",
      "3/3 - 0s - loss: 1.3443 - accuracy: 0.5027 - val_loss: 1.8168 - val_accuracy: 0.3818\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 1.69391\n",
      "Epoch 79/500\n",
      "3/3 - 0s - loss: 1.2901 - accuracy: 0.5155 - val_loss: 1.8224 - val_accuracy: 0.3955\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 1.69391\n",
      "Epoch 80/500\n",
      "3/3 - 0s - loss: 1.3136 - accuracy: 0.5000 - val_loss: 1.7541 - val_accuracy: 0.3894\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 1.69391\n",
      "Epoch 81/500\n",
      "3/3 - 0s - loss: 1.2316 - accuracy: 0.5482 - val_loss: 1.8852 - val_accuracy: 0.3758\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 1.69391\n",
      "Epoch 82/500\n",
      "3/3 - 0s - loss: 1.2801 - accuracy: 0.5173 - val_loss: 1.8549 - val_accuracy: 0.3894\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 1.69391\n",
      "Epoch 83/500\n",
      "3/3 - 0s - loss: 1.2357 - accuracy: 0.5355 - val_loss: 1.8225 - val_accuracy: 0.3970\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 1.69391\n",
      "Epoch 84/500\n",
      "3/3 - 0s - loss: 1.2441 - accuracy: 0.5164 - val_loss: 1.8924 - val_accuracy: 0.3636\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 1.69391\n",
      "Epoch 85/500\n",
      "3/3 - 0s - loss: 1.1997 - accuracy: 0.5491 - val_loss: 1.9295 - val_accuracy: 0.3924\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 1.69391\n",
      "Epoch 86/500\n",
      "3/3 - 0s - loss: 1.1904 - accuracy: 0.5391 - val_loss: 2.0808 - val_accuracy: 0.3848\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 1.69391\n",
      "Epoch 87/500\n",
      "3/3 - 0s - loss: 1.2112 - accuracy: 0.5273 - val_loss: 1.9369 - val_accuracy: 0.3803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00087: val_loss did not improve from 1.69391\n",
      "\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.004095999523997307.\n",
      "Epoch 00087: early stopping\n",
      "=========== Supervised Training Completed! ==========\n",
      "Save model to 'saved_models/weight_sup.hdf5'\n"
     ]
    }
   ],
   "source": [
    "sup_model = train_supervised(X_train_labeled, Y_train_labeled, X_val_labeled, Y_val_labeled, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c0a8a",
   "metadata": {},
   "source": [
    "### Compare the result of our model and the supervised training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dab40e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 2s 12ms/step - loss: 1.6183 - accuracy: 0.4254\n",
      "Tuned model score: [1.6183435916900635, 0.4254363775253296]\n",
      "108/108 [==============================] - 2s 11ms/step - loss: 1.6820 - accuracy: 0.3877\n",
      "Supervised model score: [1.6820265054702759, 0.3876909017562866]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weight_tune = \"./saved_models/weight_tune.hdf5\"\n",
    "weight_sup = \"./saved_models/weight_sup.hdf5\"\n",
    "\n",
    "compare_tune_and_sup(weight_tune, weight_sup, X_test, Y_test, test_idx, snrs, lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641cfde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb425fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cb4a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b7d6dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c0756b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.4",
   "language": "python",
   "name": "tf2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
